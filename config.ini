[API]
# API to use: groq, ollama, openai, sambanova, mistral
# Add different engine_xxx settings if you need different defaults for different functionality
engine_default = sambanova

# API Keys
groq_key = gsk_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
openai_key = sk-proj-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
ollama_key = ollama_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
sambanova_key = xxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
mistral_key = xxxxxxxxxxxxxxxxxxxxxxxxxxxxxx

[Models]
# Default models
groq_default = llama-3.3-70b-versatile
ollama_default = llama3.2:3b
openai_default = gpt-4o-mini
sambanova_default = Meta-Llama-3.1-70B-Instruct
mistral_default = ministral-8b-latest

# List of allowed models
groq_allowed = llama3-70b-8192, llama3-8b-8192, mixtral-8x7b-32768, gemma-7b-it, gemma2-9b-it, whisper-large-v3,  distil-whisper-large-v3-en, llama-3.2-1b-preview, llama-3.2-3b-preview, llama-3.2-11b-vision-preview, llama-3.2-90b-vision-preview, llama-guard-3-8b, llama-3.3-70b-versatile, llama-3.1-70b-specdec

ollama_allowed = llama3:8b, phi3, phi3:14b, mixtral:8x7b, mistral:7b, gemma:2b, gemma:7b, codegemma:7b, command-r:35b, llava:7b, llava:13b, dolphin-llama3:8b, wizardlm2:7b, stable-code:3b, codellama:13b, deepseek-coder:7b, orca-mini:3b, deepseek-coder-v2:16b, llama3.2:1b, llama3.2:3b, granite3-dense:8b

openai_allowed = gpt-4o-mini, gpt-4o, gpt-3.5-turbo-16k, gpt-4-turbo

sambanova_allowed = Meta-Llama-3.1-8B-Instruct, Meta-Llama-3.1-70B-Instruct, Meta-Llama-3.1-405B-Instruct

mistral_allowed = ministral-3b-latest, ministral-8b-latest, mistral-large-latest, mistral-small-latest, codestral-latest, mistral-embed, pixtral-12b-2409, open-mistral-nemo, open-codestral-mamba, open-mistral-7b, open-mixtral-8x7b, open-mixtral-8x22b

[Settings]
temperature_default = 0.5
max_tokens_default = 2048
